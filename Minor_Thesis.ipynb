{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Minor Thesis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "20d7nwRRG2M3"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import plotly.offline as py \n",
        "import plotly.graph_objs as go \n",
        "py.init_notebook_mode(connected=True)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "torch.manual_seed(15)\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "import seaborn as sns\n",
        "from time import time\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.layers import Input, Dropout, TimeDistributed, RepeatVector\n",
        "from keras.models import Model\n",
        "from keras import regularizers\n",
        "pip install pyod\n",
        "from pyod.models.auto_encoder import AutoEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoTYe9s5ORC0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw26X9pfryf8"
      },
      "source": [
        "classes = pd.read_csv(\"/content/gdrive/My Drive/elliptic_bitcoin_dataset/elliptic_txs_classes.csv\")\n",
        "features = pd.read_csv(\"/content/gdrive/My Drive/elliptic_bitcoin_dataset/elliptic_txs_features.csv\", header = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8jSyVOxr9lm"
      },
      "source": [
        "features.columns = ['txId', 'time_step'] + [f'txn{i}' for i in range(93)] + [f'agg{i}' for i in range(72)]\n",
        "features_class = pd.merge(features, classes, left_on = \"txId\", right_on = \"txId\", how = \"left\")\n",
        "features_class = features_class.rename(columns = {\"class\": \"target\"})\n",
        "features_class[\"target\"] = features_class[\"target\"].replace({\"1\": 1, \"2\": 0, \"unknown\": -1})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkCuMJVyr9iN"
      },
      "source": [
        "g = pd.DataFrame(features_class.groupby([\"target\"]).count()[\"txId\"]).reset_index()\n",
        "sns.barplot(x = \"target\", y = \"txId\", data = g)\n",
        "plt.title('Transaction label');\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgDVwUKSr9fj"
      },
      "source": [
        "grouped = features_class.groupby(['time_step', 'target'])['txId'].count().reset_index().rename(columns = {'txId': 'count'})\n",
        "sns.lineplot(x = 'time_step', y='count', hue='target', data = grouped);\n",
        "plt.legend(loc = (1.01, 0.78));\n",
        "plt.title('Number of transactions in each time step by class');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeQs7jvbr9cw"
      },
      "source": [
        "count_by_class = features_class[[\"time_step\",'target']].groupby(['time_step','target']).size().to_frame().reset_index()\n",
        "illicit_count = count_by_class[count_by_class['target'] == 0]\n",
        "licit_count = count_by_class[count_by_class['target'] == 1]\n",
        "unknown_count = count_by_class[count_by_class['target'] == -1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXcyEu20r9ZY"
      },
      "source": [
        "x_list = list(range(1,50))\n",
        "fig = go.Figure(data = [\n",
        "    go.Bar(name = \"Unknown\", x = x_list, y = unknown_count[0], marker = dict(color = 'rgba(120, 100, 180, 0.6)',\n",
        "        line = dict(\n",
        "            color = 'rgba(120, 100, 180, 1.0)', width = 1))),\n",
        "    go.Bar(name = \"Licit\", x = x_list, y = licit_count[0], marker = dict(color = 'rgba(246, 78, 139, 0.6)',\n",
        "        line = dict(\n",
        "            color = 'rgba(246, 78, 139, 1.0)', width = 1))),\n",
        "    go.Bar(name = \"Illicit\", x = x_list, y = illicit_count[0], marker = dict(color = 'rgba(58, 190, 120, 0.6)',\n",
        "        line = dict(\n",
        "            color = 'rgba(58, 190, 120, 1.0)', width = 1)))\n",
        "\n",
        "])\n",
        "fig.update_layout(barmode = 'stack', xaxis_title = \"time_step\", yaxis_title = \"Transactions by class\", title = \"Number of transactions per timestep by class\")\n",
        "py.iplot(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khzaWBKUrzcH"
      },
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn9XQ83dOdPl"
      },
      "source": [
        "classes = pd.read_csv(\"/content/gdrive/My Drive/elliptic_bitcoin_dataset/elliptic_txs_classes.csv\")\n",
        "features = pd.read_csv(\"/content/gdrive/My Drive/elliptic_bitcoin_dataset/elliptic_txs_features.csv\", header = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4pHNoY6EUJ_"
      },
      "source": [
        "local_features = [\"local_feat_\"+ str(i) for i in range(2,95)]\n",
        "nonlocal_features = [\"nonlocal_feat_\"+ str(i) for i in range(1,73)]\n",
        "features.columns = [\"txId\",\"time_step\"] + local_features + nonlocal_features\n",
        "features = pd.merge(features, classes, left_on = \"txId\", right_on = \"txId\", how = 'left')\n",
        "features['class'] = features['class'].replace({\"unknown\": 0})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwTs8E_zOycR"
      },
      "source": [
        "data = features[(features['class'] == '1') | (features['class'] == '2')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNS5GHJkO09o"
      },
      "source": [
        "X = data[local_features + nonlocal_features]\n",
        "data['class'] = data['class'].replace({\"2\": 0})\n",
        "y = data['class']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 15, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Qxo2tTGO30B"
      },
      "source": [
        "#Logistic Regression\n",
        "reg = LogisticRegression().fit(X_train, y_train)\n",
        "model = reg.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-p01iNPLHn7"
      },
      "source": [
        "print(classification_report(y_test, model))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zk8ctpi-qPH"
      },
      "source": [
        "f1_score(y_test, model, average = 'micro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LOKt6i7KjrF"
      },
      "source": [
        "cmatrix = metrics.confusion_matrix(y_test, model)\n",
        "print(cmatrix)\n",
        "fig, ax = plot_confusion_matrix(conf_mat = cmatrix)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Okq-G9M_Alvc"
      },
      "source": [
        "k = reg.predict_proba(X_test)[:, 1]\n",
        "auc = roc_auc_score(y_test, preds)\n",
        "fped, tped, threshold = metrics.roc_curve(y_test, k)\n",
        "plt.figure()\n",
        "plt.plot(fped, tped, label = 'Logistic Regression (area = %0.2f)' % auc)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('ROC_AUC CURVE')\n",
        "plt.legend(loc = \"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4_1fDSkrc_L"
      },
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l2H25RaPqI-"
      },
      "source": [
        "model = RandomForestClassifier().fit(X_train, y_train)\n",
        "preds1 = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63zI2FhJmPCQ"
      },
      "source": [
        "print(classification_report(y_test, preds1))\n",
        "cm1 = metrics.confusion_matrix(y_test, preds1)\n",
        "print(cm1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzb7uUeg_VeC"
      },
      "source": [
        "f1_score(y_test, preds1, average = 'micro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8B8285tUUtX"
      },
      "source": [
        "fig, ax = plot_confusion_matrix(conf_mat = cm1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96EdoKvOU2bm"
      },
      "source": [
        "k = model.predict_proba(X_test)[:,1]\n",
        "auc = roc_auc_score(y_test, preds1)\n",
        "fped, tped, threshold = metrics.roc_curve(y_test, k)\n",
        "plt.figure()\n",
        "plt.plot(fped, tped, label = 'Random Forest (area = %0.2f)' % auc)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('ROC_AUC CURVE')\n",
        "plt.legend(loc = \"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtcXbBfoxxur"
      },
      "source": [
        "MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0895SF9PvwP"
      },
      "source": [
        "class LoadData(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "         \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        features = self.X.iloc[idx]\n",
        "        features = np.array([features])\n",
        "        label = y.iloc[idx]\n",
        "\n",
        "        return features,label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRRK-JUTP33r"
      },
      "source": [
        "train = LoadData(X_train, y_train)\n",
        "trloader = DataLoader(train, batch_size = 128, shuffle = True)  \n",
        "test = LoadData(X_test, y_test)\n",
        "tsloader = DataLoader(test, batch_size = 128, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzsHwrGGP6EB"
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden = nn.Linear(165,50 )\n",
        "\n",
        "        self.output = nn.Linear(50,1)\n",
        "        self.out = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "        x = F.relu(self.hidden(x))\n",
        "\n",
        "        x = self.out(self.output(x))\n",
        "        \n",
        "        return x\n",
        "\n",
        "model = Network()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otApOOd6P9Yo"
      },
      "source": [
        "opt = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "criterion = nn.BCELoss()\n",
        "n_epochs=10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mifzFJJQDDj"
      },
      "source": [
        "for i in range(n_epochs):\n",
        "        model.to('cuda')\n",
        "        model.train()\n",
        "        losses = 0.\n",
        "        for data in trloader:\n",
        "            x, label = data\n",
        "            x, label = x.cuda(), label.cuda()\n",
        "            output = model.forward(x.float())\n",
        "            output = output.squeeze()\n",
        "            ls = criterion(output.float(), label.float())\n",
        "            ls.backward()\n",
        "            opt.step()\n",
        "            losses = losses + ls.item()\n",
        "        else:\n",
        "            print(f\"Loss: {losses/len(trloader)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PsBo854Xaqt"
      },
      "source": [
        "pr = []\n",
        "for i in tsloader:\n",
        "    x, labels = data\n",
        "    x, labels = x.cuda(), labels.cuda()\n",
        "    preds = model.forward(x.float())\n",
        "    pr.extend(preds.squeeze().detach().cpu().numpy())\n",
        "\n",
        "prs = pd.Series(pr).apply(lambda x: round(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jiReadbiXA4"
      },
      "source": [
        "print(classification_report(y_test, preds2))\n",
        "cm3 = metrics.confusion_matrix(y_test, preds2)\n",
        "print(cm3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7Mhu9kFeNvj"
      },
      "source": [
        "f1_score(y_test, preds2, average = 'micro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe60BxwbeYgl"
      },
      "source": [
        "fig, ax = plot_confusion_matrix(conf_mat = cm3)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMT5LVKwerbl"
      },
      "source": [
        "auc = roc_auc_score(y_test, preds2)\n",
        "fped, tped, threshold = metrics.roc_curve(y_test, preds2)\n",
        "plt.figure()\n",
        "plt.plot(fped, tped, label = 'MLP (area = %0.2f)' % auc)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('ROC_AUC CURVE')\n",
        "plt.legend(loc = \"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyOeca9Xy27X"
      },
      "source": [
        "K-Means Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAKJlIkSag0n"
      },
      "source": [
        "classes = pd.read_csv(\"/content/gdrive/My Drive/elliptic_bitcoin_dataset/elliptic_txs_classes.csv\")\n",
        "features = pd.read_csv(\"/content/gdrive/My Drive/elliptic_bitcoin_dataset/elliptic_txs_features.csv\", header = None)\n",
        "features.columns = ['txId', 'time_step'] + [f'txn{i}' for i in range(93)] + [f'agg{i}' for i in range(72)]\n",
        "\n",
        "features_classes = pd.merge(features, classes, left_on = \"txId\", right_on = \"txId\", how = \"left\")\n",
        "features_classes = features_classes.rename(columns = {\"class\": \"target\"})\n",
        "features_classes[\"target\"] = features_classes[\"target\"].replace({\"1\": 1, \"2\": 0, \"unknown\": -1})\n",
        "\n",
        "features_classes[\"target\"].value_counts()\n",
        "\n",
        "original_Xtrain = features_classes.query('time_step < 35 and target != -1').drop(['target', \"time_step\", \"txId\"], axis =1)\n",
        "original_ytrain = features_classes.query('time_step < 35 and target != -1')['target']\n",
        "unlabeled_df_train1 = features_classes.query('time_step < 35 and target == -1').drop(['target'], axis =1)\n",
        "\n",
        "original_Xtest = features_classes.query('time_step >= 35 and target != -1').drop(['target', \"time_step\", \"txId\"], axis = 1)\n",
        "original_ytest = features_classes.query('time_step >= 35 and target != -1')['target']\n",
        "\n",
        "models = {}\n",
        "errors = []\n",
        "\n",
        "for p in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters = p)\n",
        "    kmeans.fit(original_Xtrain)    \n",
        "    models[p] = kmeans    \n",
        "    labels = kmeans.labels_\n",
        "    errors.append(kmeans.inertia_)\n",
        "    print(\"\\nk = \"+str(p))\n",
        "\n",
        "plt.style.use('seaborn')\n",
        "plt.plot(range(1, 11), errors)\n",
        "plt.xticks(range(1, 11))\n",
        "plt.xlabel(\"Clusters\")\n",
        "plt.ylabel(\"SSD\")\n",
        "plt.title(\"Elbow Method\")\n",
        "plt.show()\n",
        "\n",
        "tpr = {}\n",
        "licit = pd.value_counts(original_ytrain)[0]\n",
        "illicit = pd.value_counts(original_ytrain)[1]\n",
        "for p in models:\n",
        "    print('p='+str(1)+'\\n')\n",
        "    tpr[p] = models.get(p).predict(original_Xtrain)\n",
        "    print(\"For p =\" + str(p))\n",
        "    m = 0\n",
        "    c = {}\n",
        "    n = set(np.where(original_ytrain == 1)[0])\n",
        "    for i in tpr[p]:\n",
        "        c[i] = c.get(i, 0) + 0\n",
        "        if m in n:\n",
        "            c[i] = c.get(i, 0) + 1\n",
        "        m = m + 1\n",
        "    for key, value in sorted(c.items()):\n",
        "        good = len((np.where(tpr[p] == key)[0]))-value\n",
        "        print('Cluster '+str(key+1)+': \\t Illicit: '+str(value)+ ' ('+str(round((value*100)/illicit,3))+'%)' +' \\t Licit: '+str(good)+' ('+str(round((good*100)/licit,3))+'%)\\n')\n",
        "    print('\\n')\n",
        "\n",
        "pr = {}\n",
        "licit = pd.value_counts(original_ytest)[0]\n",
        "illicit = pd.value_counts(original_ytest)[1]\n",
        "for p in models:\n",
        "    print('p ='+str(p)+'\\n')\n",
        "    pr[p] = models.get(p).predict(original_Xtest)\n",
        "    print(\"For p =\"+ str(p))\n",
        "    m = 0\n",
        "    c = {}\n",
        "    n = set(np.where(original_ytest == 1)[0])\n",
        "    for i in pr[p]:\n",
        "        c[i] = c.get(i, 0) + 0\n",
        "        if m in n:\n",
        "            c[i] = c.get(i, 0) + 1\n",
        "        m = m + 1\n",
        "    for key, value in sorted(c.items()):\n",
        "        good = len((np.where(pr[p] == key)[0]))-value\n",
        "        print('Cluster '+str(key+1)+': \\t Illicit: '+str(value)+ ' ('+str(round((value*100)/illicit,3))+'%)' +' \\t Licit: '+str(good)+' ('+str(round((good*100)/licit,3))+'%)\\n')\n",
        "    print('\\n')\n",
        "\n",
        "p = 6\n",
        "new_df = original_Xtest.copy()\n",
        "anomaly = []\n",
        "m = 0\n",
        "n = np.where(original_ytest == 1)[0]\n",
        "for i in pr[p]:\n",
        "    if m in n:\n",
        "        anomaly.append(1)\n",
        "    else:\n",
        "        anomaly.append(0)\n",
        "    m = m + 1\n",
        "    \n",
        "new_df['cluster'] = pr[p]\n",
        "new_df['anomaly'] = anomaly\n",
        "final = new_df.copy()\n",
        "\n",
        "\n",
        "print('For p ='+str(p))\n",
        "l = [1,6]\n",
        "\n",
        "prs = pr[p].copy()\n",
        "tprs = tpr[p].copy()\n",
        "\n",
        "\n",
        "if len(pd.value_counts(tprs)) > 2 and len(pd.value_counts(prs)) > 2:\n",
        "    for i in range(0, p):\n",
        "        if (i + 1) in l:\n",
        "            prs[prs == i] = -1\n",
        "            tprs[tprs == i] = -1\n",
        "        else:\n",
        "            prs[prs == i] = 0\n",
        "            tprs[tprs == i] = 0\n",
        "\n",
        "    prs[prs == -1] = 1\n",
        "    tprs[tprs == -1] = 1\n",
        "    print(pd.value_counts(tprs))\n",
        "    print(pd.value_counts(prs))\n",
        "\n",
        "print(classification_report(original_ytest, prs))\n",
        "f1_score(original_ytest, prs, average='micro')\n",
        "cm = confusion_matrix(original_ytest, prs)\n",
        "print(cm)\n",
        "fig, ax = plot_confusion_matrix(conf_mat=cm)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8irXx_6fx2U9"
      },
      "source": [
        "Autoencoders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLilZMvNjvUn"
      },
      "source": [
        "classes = pd.read_csv(\"/content/gdrive/My Drive/elliptic_bitcoin_dataset/elliptic_txs_classes.csv\")\n",
        "features = pd.read_csv(\"/content/gdrive/My Drive/elliptic_bitcoin_dataset/elliptic_txs_features.csv\", header = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS6xJeXwkSPa"
      },
      "source": [
        "tx_features = [\"tx_feat_\"+str(i) for i in range(2,95)]\n",
        "agg_features = [\"agg_feat_\"+str(i) for i in range(1,73)]\n",
        "features.columns = [\"txId\",\"time_step\"] + tx_features + agg_features\n",
        "features = pd.merge(features,classes,left_on=\"txId\",right_on=\"txId\",how='left')\n",
        "features.rename(columns = {\"class\" : \"target\"}, inplace = True)\n",
        "features['target'] = features['target'].apply(lambda x: '0' if x == \"unknown\" else x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCJAulw0kVv2"
      },
      "source": [
        "data = features[(features['target']=='1') | (features['target']=='2')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8bADaVfkjTQ"
      },
      "source": [
        "X = data[tx_features+agg_features]\n",
        "y = data['target']\n",
        "y = y.apply(lambda x: 0 if x == '2' else 1 )\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 15, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmvB9S1qMVMX"
      },
      "source": [
        "epochs = 100\n",
        "random_state = 42\n",
        "batch_size = 256\n",
        "outliers_fraction = 0.15\n",
        "\n",
        "def fit_model(X_train):\n",
        "    clf = AutoEncoder(hidden_neurons=[6, 4, 4, 6], \n",
        "                      hidden_activation='tanh', \n",
        "                      output_activation='sigmoid', \n",
        "                      loss='mean_squared_logarithmic_error', \n",
        "                      optimizer='adam',\n",
        "                      epochs=epochs, \n",
        "                      batch_size=batch_size, \n",
        "                      dropout_rate=0.1, \n",
        "                      l2_regularizer=0.000001, \n",
        "                      validation_size=0.20, \n",
        "                      preprocessing=False, \n",
        "                      verbose=1, \n",
        "                      random_state=random_state, \n",
        "                      contamination=outliers_fraction)\n",
        "    clf.fit(X_train)\n",
        "    return clf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkQTdEk0Mdc1"
      },
      "source": [
        "training_evaluations = {}\n",
        "test_evaluations = {}\n",
        "model = {}\n",
        "\n",
        "clf = fit_model(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU49Ja-oUbDq"
      },
      "source": [
        "y_test_pred = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiaswPHrz82O"
      },
      "source": [
        "cm = metrics.confusion_matrix(y_test, y_test_pred)\n",
        "print(cm)\n",
        "print(classification_report(y_test, y_test_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PH-XCkHQoyF9"
      },
      "source": [
        "f1_score(y_test, y_test_pred, average='micro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lD7v7hQ0rAg"
      },
      "source": [
        "fig, ax = plot_confusion_matrix(conf_mat=cm)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpF8wUx80zQE"
      },
      "source": [
        "k = clf.predict_proba(X_test)[:,1]\n",
        "auc = roc_auc_score(y_test, y_test_pred)\n",
        "fped, tped, threshold = metrics.roc_curve(y_test, k)\n",
        "plt.figure()\n",
        "plt.plot(fped, tped, label = 'Autoencoder (area = %0.2f)' % auc)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('ROC_AUC CURVE')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8lmI0nax6Gn"
      },
      "source": [
        "LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6vWKXmyvxVL"
      },
      "source": [
        "classes = pd.read_csv(\"/content/gdrive/My Drive/elliptic_bitcoin_dataset/elliptic_txs_classes.csv\")\n",
        "features = pd.read_csv(\"/content/gdrive/My Drive/elliptic_bitcoin_dataset/elliptic_txs_features.csv\", header = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDXlHtrYTHcq"
      },
      "source": [
        "features.columns = ['txId', 'time_step'] + [f'txn{i}' for i in range(93)] + [f'agg{i}' for i in range(72)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gez1oOvJY_zo"
      },
      "source": [
        "features_classes = pd.merge(features, classes, left_on = \"txId\", right_on = \"txId\", how = \"left\")\n",
        "features_classes = features_classes.rename(columns = {\"class\": \"target\"})\n",
        "features_classes[\"target\"] = features_classes[\"target\"].replace({\"1\": 1, \"2\": 0, \"unknown\": -1})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oRXUZoLZBO6"
      },
      "source": [
        "X_train1 = features_classes.query('target == 0').drop(['target', \"time_step\", \"txId\"], axis =1)\n",
        "y_train1 = features_classes.query('target == 0')['target']\n",
        "X_test1 = features_classes.query('target == 1').drop(['target', \"time_step\", \"txId\"], axis = 1)\n",
        "y_test1 = features_classes.query('target == 1')['target']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o3y_qK3hE0x"
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "x_train1 = scaler.fit_transform(X_train1)\n",
        "x_test1 = scaler.fit_transform(X_test1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aO_aF7qNZIP8"
      },
      "source": [
        "x_train = x_train1.reshape(42019, 1, 165)\n",
        "x_test = x_test1.reshape(4545, 1, 165)\n",
        "y_train1.shape, y_test1.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR2KACreJYMW"
      },
      "source": [
        "y_train1.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYrViktPACVg"
      },
      "source": [
        "LSTM Auto Encoder - [16, 4, 4, 16]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV28rDlLe1QC"
      },
      "source": [
        "model10 = Sequential([\n",
        "    LSTM(128, input_shape=(1, 165)),\n",
        "    Dropout(0.2),\n",
        "    RepeatVector(1),\n",
        "    LSTM(128, return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    TimeDistributed(Dense(165))                 \n",
        "])\n",
        "\n",
        "model.compile(loss = 'mae', optimizer = 'adam', metrics = \"acc\")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "168M3rmpjT3s"
      },
      "source": [
        "stp = tf.keras.callbacks.EarlyStopping(restore_best_weights = True, patience = 5)\n",
        "Model = model.fit(x_train, y_train1, epochs = 100, batch_size = 256, validation_split = 0.05, callbacks = [stp], shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tuEZgVk_0po"
      },
      "source": [
        "plt.plot(model.history.history['loss'], Label = 'Loss')\n",
        "plt.plot(model.history.history['val_loss'], Label = 'Val_Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid()\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1APkrY_N9L_e"
      },
      "source": [
        "Result = model.evaluate(x_test, y_test1, batch_size = 256)\n",
        "print(Result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyA1Av_0ml3c"
      },
      "source": [
        "Xtr = model.predict(x_train)\n",
        "Xtr = Xtr.reshape(Xtr.shape[0], Xtr.shape[2])\n",
        "Xtr = pd.DataFrame(Xtr, columns = X_train1.columns)\n",
        "Xtr.index = X_train1.index\n",
        "Xts = model.predict(x_test)\n",
        "Xts = Xts.reshape(Xts.shape[0], Xts.shape[2])\n",
        "Xts = pd.DataFrame(Xts, columns = X_test1.columns)\n",
        "Xts.index = X_test1.index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmA8wHhGrPUo"
      },
      "source": [
        "prtrain = pd.DataFrame(index = X_train1.index)\n",
        "newtrain = x_train.reshape(x_train.shape[0], x_train.shape[2])\n",
        "prtrain[\"Loss_mae\"] = np.mean(np.abs(Xtr - newtrain), axis = 1)\n",
        "plt.title(\"Loss_mae Distribuion\")\n",
        "sns.distplot(prtrain[\"Loss_mae\"], bins = 20, kde = True, color = \"blue\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1F2Lb0fKWUS"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n1lzfM9we8x"
      },
      "source": [
        "prtest = pd.DataFrame(index = X_test1.index)\n",
        "newtest = x_test.reshape(x_test.shape[0], x_test.shape[2])\n",
        "prtest[\"Loss_mae\"] = np.mean(np.abs(prtest - newtest), axis = 1)\n",
        "prtest[\"Threshold\"] = 0.35\n",
        "prtest[\"Anomaly\"] = prtest[\"Loss_mae\"] > prtest[\"Threshold\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77gP8wwX2ZqU"
      },
      "source": [
        "new data = pd.concat(prtrain, prtest])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWiuDxI22Nh6"
      },
      "source": [
        "newdata.plot(logy = True, color = [\"blue\", \"red\"]);"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}